{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installation"],"metadata":{"id":"ua8588uMmL4d"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNix10_2f-3V","executionInfo":{"status":"ok","timestamp":1720208799848,"user_tz":420,"elapsed":24105,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"6dc29468-8c70-476c-ce10-1516a6d6a8eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Collecting keras==2.2.4\n","  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.5/312.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.4) (1.25.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.4) (1.11.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras==2.2.4) (1.16.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras==2.2.4) (6.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==2.2.4) (3.9.0)\n","Collecting keras-applications>=1.0.6 (from keras==2.2.4)\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras==2.2.4)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.2\n"]}],"source":["!pip install tensorflow\n","!pip install keras==2.2.4"]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"vs-oRxxUbbVY"}},{"cell_type":"code","source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"metadata":{"id":"qj0Rrnrnmft2","executionInfo":{"status":"ok","timestamp":1720208803501,"user_tz":420,"elapsed":190,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8szuXq5-d8t","executionInfo":{"status":"ok","timestamp":1720208825446,"user_tz":420,"elapsed":20213,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"52e47ce6-2f35-4aa6-9e27-8f6c0685cdac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","def generate_dtypes(col_names, nominal_names):\n","\tdtypes = {}\n","\tfor col_name in col_names:\n","\t\tif col_name in nominal_names:\n","\t\t\tdtypes[col_name] =  str\n","\t\telse:\n","\t\t\tdtypes[col_name] = np.float32\n","\treturn dtypes\n","\n","#Mark the nominal columns and consolidate the data (extract all the nominal columns)\n","def combine_dataset(files, col_names, nominal_names, processed = False):\n","\tdtypes = {}\n","\tif processed == False:\n","\t\tdtypes = generate_dtypes(col_names, nominal_names)\n","\telse:\n","\t\tfor col_name in col_names:\n","\t\t\tdtypes[col_name] = np.float32\n","\n","\trecords = []\n","\tfor file in files:\n","\t\tdata = pd.read_csv(file, header = None, names = col_names, dtype = dtypes)\n","\t\trecords.append(data)\n","\n","  #When there is no index, concat adds them together regardless of the column names,\n","\trecords_all = pd.concat(records)\n","\n","\treturn records_all\n","\n","## Make new col names for categorical features after one-hot encoding\n","def get_nominal_names(dataset, cols_nominal):\n","\t# data_nominal = dataset[cols_nominal]\n","\n","\tnew_col_names = []\n","\tfor col_name in cols_nominal:\n","\t\tname_unique = sorted(dataset[col_name].unique())  #Different values for noun columns\n","\t\tnew_col_name = [col_name + '_' + x for x in name_unique]\n","\t\tnew_col_names.extend(new_col_name)\n","\n","\treturn new_col_names\n","\n","#Remove the unimportant feature, one-hot encoding, and convert the attack class to numeric\n","def select_feature_and_encoding(dataset, cols_to_drop, cols_nominal, cols_nominal_all):\n","\n","\t# Drop the features has no meaning such as src ip.\n","\tfor cols in cols_to_drop:\n","\t\tdataset.drop(cols, axis = 1, inplace = True)\n","\n","\t# Save the label and then drop it from dataset\n","\tlabel_10 = dataset['label_10']\n","\tlabel_2 = dataset['label_2']\n","\tdataset.drop('label_2', axis = 1, inplace = True)\n","\tdataset.drop('label_10', axis = 1, inplace = True)\n","\n","\t# replace the label with specific code\n","\treplace_dict = { np.nan: 0, 'Analysis': 1, 'Backdoors': 2, 'Backdoor': 2, 'DoS': 3,\n","                    'Exploits':4,' Fuzzers': 5, ' Fuzzers ':5, 'Generic': 6,\n","                    'Reconnaissance': 7, ' Shellcode ':8, 'Shellcode': 8,\n","                    'Worms':9, ' Reconnaissance ': 7,}\n","\tnew_label_10 = label_10.replace(replace_dict)\n","\tnew_label_10.to_frame()\n","\tlabel_2.to_frame\n","\tdel label_10\n","\n","\t# replace the lost values\n","\treplace_dict = {np.nan: 0, ' ': 0}\n","\tfor cols in ['ct_ftp', 'ct_flw', 'is_ftp']:\n","\t\tdataset[cols] = dataset[cols].replace(replace_dict)\n","\n","\t# 'is_ftp' column is wrong, correct it(I found that the value of it is\n","\t# all the same with ct_ftp_cmd, so if the value is not 0, is_ftp should\n","\t# be 1)\n","\tfor x in dataset['is_ftp']:\n","\t\tif x != 0:\n","\t\t\tx = 1\n","\n","\t# select and process the categorical features\n","\tdata_nominal = dataset[cols_nominal]  #cols_nominal = ['proto', 'service', 'state']\n","\tdata_temp_1 = data_nominal.apply(LabelEncoder().fit_transform)\n","\tdel data_nominal\n","\n","\tnew_col_names = get_nominal_names(dataset, cols_nominal)\n","\tfor col_name in cols_nominal:\n","\t\t# name_unique = sorted(dataset[col_name].unique())\n","\t\t# new_col_name = [col_name + '_' + x for x in name_unique]\n","\n","\t\t# new_col_names.extend(new_col_name)\n","\t\tdataset.drop(col_name, axis = 1, inplace = True)\n","\n","\t#one-hot\n","\tenc = OneHotEncoder()\n","\tdata_temp_2 = enc.fit_transform(data_temp_1)\n","\tdel data_temp_1\n","\n","\tdata_encoded = pd.DataFrame(data_temp_2.toarray(), columns = new_col_names)\n","\tdel data_temp_2\n","\n","\t# complement the nominal columns\n","\tdiff = set(cols_nominal_all) - set(new_col_names)\n","\n","\tif diff:\n","\t\tfor cols in diff:\n","\t\t\tdata_encoded[cols] = 0.\n","\t\tdata_encoded = data_encoded[cols_nominal_all]\n","\n","\tdataset = dataset.join(data_encoded)\n","\tdel data_encoded\n","\n","\tdataset = dataset.join(new_label_10)\n","\tdataset = dataset.join(label_2)\n","\n","\treturn dataset  #Complete data set (including data and labels)\n","\n","#Split the training set and test set and save the file as a CSV file\n","def split_dataset(dataset, file_train, file_test):\n","\n","\tcols = dataset.columns\n","\t#trainset, testset = train_test_split(dataset, test_size = 0.2)\n","\ttrainset, testset = train_test_split(dataset, test_size = 0.2, random_state = 40, stratify = dataset['label_10'])\n","\ttrain = pd.DataFrame(trainset, columns = cols)\n","\ttest = pd.DataFrame(testset, columns = cols)\n","\n","\ttrain.to_csv(file_train)\n","\ttest.to_csv(file_test)\n","\n","#Standardize, and save the file in CSV and tf formats\n","def scaling(files_train, files_test, col_names_scaling, scaling_type):\n","\n","\tif scaling_type == 'min_max':\n","\t\tscaler = MinMaxScaler()\n","\t\tfile_folder = 'min_max/'\n","\telse:\n","\t\tscaler = StandardScaler()\n","\t\tfile_folder = 'normalized/'\n","\n","\tif not os.path.exists(file_folder):\n","\t\tos.mkdir(file_folder)\n","\tcols = []\n","\tfor file in files_train:\n","\t\t# col 0 is the index in the file\n","\t\ttrainset = pd.read_csv(file, index_col = 0, dtype = np.float32)\n","\t\tif len(cols) == 0:\n","\t\t\tcols = trainset.columns\n","\t\tscaler.partial_fit(trainset[col_names_scaling])\n","\n","\tdel trainset\n","\tcols_keep = list(set(cols) - set(col_names_scaling))\n","\n","\tfor file in files_train:\n","\t\ttrainset = pd.read_csv(file, dtype = np.float32)\n","\t\ttrain_scaled = scaler.transform(trainset[col_names_scaling])\n","\t\ttrain_changed = pd.DataFrame(train_scaled, columns = col_names_scaling)\n","\t\ttrain_unchanged = trainset[cols_keep]\n","\t\ttrainset_final = pd.concat((train_changed, train_unchanged),\n","\t\t                        axis = 1)\n","\t\ttrainset_final = trainset_final[cols]\n","\t\tprint(\"train:\",trainset_final.shape)  #trainset shape\n","\t\tfile_csv = file_folder + file\n","\t\ttrainset.to_csv(file_csv, index = False)\n","\t\tlen_tail = len('.csv')\n","\t\tfile_tfr = file_folder + file[:-1 * len_tail] + '.tfrecords'\n","\t\tmake_tfrecords(trainset_final, file_tfr)\n","\n","\tfor file in files_test:\n","\t\ttestset = pd.read_csv(file, dtype = np.float32)\n","\t\ttest_scaled = scaler.transform(testset[col_names_scaling])\n","\t\ttest_changed = pd.DataFrame(test_scaled, columns = col_names_scaling)\n","\t\ttest_unchanged = testset[cols_keep]\n","\t\ttestset_final = pd.concat((test_changed, test_unchanged),axis = 1)\n","\t\ttestset_final = testset_final[cols]\n","\t\tprint(\"test:\",testset_final.shape)\n","\t\tfile_csv = file_folder + file\n","\t\ttestset.to_csv(file_csv, index = False)\n","\t\tlen_tail = len('.csv')\n","\t\tfile_tfr = file_folder + file[:-1 * len_tail] + '.tfrecords'\n","\t\tmake_tfrecords(testset_final, file_tfr)\n","\n","#Save the file in tf format\n","def make_tfrecords(dataset, file_to_save):\n","\n","\ttry:\n","\t\tdata = dataset.values\n","\texcept:\n","\t\tdata = dataset\n","\twith tf.io.TFRecordWriter(file_to_save) as writer:\n","\t\tfor rows in data:\n","\t\t\tfeatures, label_10, label_2 = rows[:-2], rows[-2], rows[-1]\n","\t\t\tfeature = {'features': tf.train.Feature(float_list = tf.train.FloatList(value = features)),\n","\t\t\t           'label_2': tf.train.Feature(float_list = tf.train.FloatList(value = [label_2])),\n","\t\t\t           'label_10': tf.train.Feature(float_list = tf.train.FloatList(value = [label_10]))}\n","\t\t\texample = tf.train.Example(features = tf.train.Features(feature = feature))\n","\t\t\twriter.write(example.SerializeToString())\n","\n","def next_batch(filename, batch_size):\n","\n","\tlen_feature = 202  #Number of features (not including tags)\n","\tlen_label = 1 #The length of the label\n","\n","\tdef read_data(examples):\n","\t\tfeatures = {\"features\": tf.io.FixedLenFeature([len_feature], tf.float32),\n","                    \"label_2\": tf.io.FixedLenFeature([len_label], tf.float32),\n","                    \"label_10\": tf.io.FixedLenFeature([len_label], tf.float32)}\n","\t\tparsed_features = tf.io.parse_single_example(examples, features)\n","\t\treturn parsed_features['features'], parsed_features['label_2'], \\\n","               parsed_features['label_10']\n","\n","\tdata = tf.data.TFRecordDataset(filename)\n","\tdata = data.map(read_data)\n","\tdata = data.batch(batch_size)\n","\titerator = iter(data) #data.make_one_shot_iterator()\n","\tnext_data, next_label_2, next_label_10 = iterator.get_next()\n","\n","\treturn next_data, next_label_10, next_label_2\n","\n","\n","if __name__ == '__main__':\n","\n","\tfile_folder = '/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/'  #The location where the original file was read\n","\tcol_names = ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur',\n","\t             'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss',\n","\t             'service', 'sload', 'dload', 'spkts', 'dpkts', 'swin', 'dwin',\n","\t             'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',\n","\t             'res_bdy_len', 'sjit', 'djit', 'stime', 'ltime', 'sintpkt',\n","\t             'dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips',\n","\t             'ct_state_ttl', 'ct_flw', 'is_ftp', 'ct_ftp', 'ct_srv_src',\n","\t             'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport',\n","\t             'ct_dst_sport', 'ct_dst_src', 'label_10', 'label_2']    #listed name\n","\n","\tcols_to_drop = ['srcip', 'dstip', 'stime', 'ltime', 'sport', 'dsport']\n","\n","\tcols_nominal = ['proto', 'service', 'state']   #Nominal features\n","\n","\tfiles = [file_folder + 'UNSW-NB15_' + str(i+1) + '.csv' for i in range(4)]\n","\n","\tnominal_names = set(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state',\n","\t\t\t\t                 'service', 'ct_ftp', 'label_10'])  #Nominal column\n","\tdataset = combine_dataset(files, col_names, nominal_names)\n","\t# feature dimension changes from 47 to 208\n","\tcols_nominal_all = get_nominal_names(dataset, cols_nominal)\n","\tdel dataset\n","\n","\tfile_tail = len('.csv')\n","\tfile_head = len(file_folder + 'UNSW-NB15_')\n","\tnominal_names = set(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state',\n","\t\t\t                 'service', 'is_ftp', 'ct_flw', 'ct_ftp', 'label_10'])\n","\tdtypes = generate_dtypes(col_names, nominal_names)\n","\n","\tfor file in files:\n","\t\t# 1_train.csv, 2_train.cvs, 3_train.csv, 4_train.csv\n","\t\tfile_train = file[file_head:-1 * file_tail] + '_train.csv'\n","    #Each file is split out of the training set and test set, CSV file\n","\t\t# 1_test.csv, 1_test.cvs, 1_test.csv, 1_test.csv\n","\t\tfile_test = file[file_head: -1 * file_tail] + '_test.csv'\n","\t\tdataset = pd.read_csv(file, header = None, names = col_names, dtype = dtypes)\n","\t\tdataset = select_feature_and_encoding(dataset, cols_to_drop, cols_nominal,\n","\t\t                                          cols_nominal_all)\n","\t\tsplit_dataset(dataset, file_train, file_test)\n","\n","\tcols_unchanged = ['is_ftp', 'is_sm_ips'] + cols_nominal +\\\n","\t                 cols_to_drop + ['label_2', 'label_10']\n","\tcols_scaling = [x for x in col_names if x not in cols_unchanged]\n","\n","\tfiles_train = [str(x + 1) + '_train.csv' for x in range(4)]\n","\tfiles_test = [str(x + 1) + '_test.csv' for x in range(4)]\n","\n","\tscaling(files_train, files_test, cols_scaling, 'std')  #standardized\n","\n","\tfile_folder = 'normalized/' #A folder where data is stored after standardization\n","\tfiles_train = [file_folder + str(x + 1) + '_train.tfrecords' for x in range(4)]\n","\tfiles_test = [file_folder + str(x + 1) + '_test.tfrecords' for x in range(4)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r8_XgBBDUfq9","executionInfo":{"status":"ok","timestamp":1720210296565,"user_tz":420,"elapsed":221768,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"18a965b9-4d15-44ad-c08d-9e601e895e8d","collapsed":true},"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]},{"output_type":"stream","name":"stdout","text":["train: (560000, 204)\n","train: (560000, 204)\n","train: (560000, 204)\n","train: (352035, 204)\n","test: (140001, 204)\n","test: (140001, 204)\n","test: (140001, 204)\n","test: (88009, 204)\n"]}]},{"cell_type":"code","source":["#Integrate the four separate data sets\n","def make_whole_datasets(tfrecords_train, num_train_example, tfrecords_test,\n","                        num_test_example):\n","\n","    data_train, label_10_train, label_2_train = next_batch(tfrecords_train, num_train_example)\n","    data_test, label_10_test, label_2_test = next_batch(tfrecords_test, num_test_example)\n","    # with tf.compat.v1.Session() as sess:\n","        # data, label_10, label_2 = sess.run([data_train, label_10_train,label_2_train])\n","    data, label_10, label_2 = [data_train, label_10_train, label_2_train]\n","    dataset = np.concatenate([data, label_10, label_2], axis = 1)\n","\n","    #trainset, valiset = train_test_split(dataset, test_size = 254004,stratify=dataset['label_10'])\n","    trainset, valiset = train_test_split(dataset, test_size = 0.125, random_state = 40, stratify = dataset[:,-2])\n","    print(\"train:\", trainset.shape)\n","    print(\"val:\", valiset.shape)\n","\n","    make_tfrecords(trainset, 'normalized/train.tfrecords')\n","    make_tfrecords(valiset, 'normalized/validation.tfrecords')\n","\n","    del trainset, valiset\n","\n","    # with tf.compat.v1.Session() as sess:\n","        # data, label_10, label_2 = sess.run([data_test, label_10_test,label_2_test])\n","    data, label_10, label_2 = [data_test, label_10_test, label_2_test]\n","    dataset = np.concatenate([data, label_10, label_2], axis = 1)\n","    print(\"test:\", dataset.shape)\n","    make_tfrecords(dataset, 'normalized/test.tfrecords')"],"metadata":{"id":"SBPkkFY9XqvW","executionInfo":{"status":"ok","timestamp":1720211427086,"user_tz":420,"elapsed":230,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["num_train_example = 2032035 #trainset size\n","num_test_example = 508012 #testset size\n","make_whole_datasets(files_train, num_train_example, files_test, num_test_example)"],"metadata":{"id":"bkM_0ovnXtJT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720211930476,"user_tz":420,"elapsed":500492,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"9ea7b6cb-9965-4643-880f-f90ccef8d502"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["train: (1778030, 204)\n","val: (254005, 204)\n","test: (508012, 204)\n"]}]},{"cell_type":"markdown","source":["# Feature Selection (DAE)"],"metadata":{"id":"jE4utr-lbudD"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class DAE(object):\n","\n","\t\"\"\"\n","\tDenoising autoencoder. Gaussian noise is added. The scale and standard deviation\n","\tof it are noise_scale and noise_std, respectively.\n","\t\"\"\"\n","\n","\tdef __init__(self, n_feature, n_hidden, noise_scale, noise_std, reg_lamda = 0.01):\n","\n","\t\tself.n_hidden = n_hidden\n","\t\tself.n_feature = n_feature\n","\t\tself.reg_lamda = reg_lamda\n","\t\tself.noise_scale = noise_scale\n","\t\tself.noise_std = noise_std\n","\n","\t\tself.data = tf.placeholder(shape = [None, n_feature],\n","\t\t                           dtype = tf.float64)\n","\t\tself.noise = self.noise_scale * tf.random_normal([n_feature], dtype = tf.float64,\n","\t\t                                               stddev = self.noise_std)\n","\t\tdata_with_noise = self.data + self.noise\n","\n","\t\tself.weight_encoder = tf.get_variable(name = 'weight_encoder',\n","\t\t\t                    shape = [self.n_feature, self.n_hidden],\n","\t\t\t                    dtype = tf.float64)\n","\t\tself.bias_encoder = tf.Variable(tf.zeros([self.n_hidden],\n","\t\t\t                                      dtype = tf.float64),\n","\t\t                                name = 'bias_encoder')\n","\n","\t\tweight_decoder = tf.get_variable(name = 'weight_decoder',\n","\t\t\t                    shape = [self.n_hidden, self.n_feature],\n","\t\t\t                    dtype = tf.float64)\n","\t\tbias_decoder = tf.Variable(tf.zeros([self.n_feature], dtype = tf.float64),\n","\t\t\t                           name = 'bias_decoder')\n","\n","\t\twith tf.name_scope('Encoder'):\n","\t\t\tdata_encoded = tf.add(tf.matmul(data_with_noise, self.weight_encoder),\n","\t\t\t\t                  self.bias_encoder)\n","\t\t\tdata_encoded = tf.nn.tanh(data_encoded)\n","\n","\t\twith tf.name_scope('Decoder'):\n","\t\t\tdata_recons = tf.add(tf.matmul(data_encoded, weight_decoder),\n","\t\t\t\t                 bias_decoder)\n","\t\t\tself.data_recons = tf.tanh(data_recons)\n","\n","\t\twith tf.name_scope('Loss'):\n","\t\t\tdiff = self.data_recons - self.data\n","\t\t\tself.loss_mse = 0.5 * tf.reduce_mean(tf.reduce_sum(diff**2, axis = 1))\n","\t\t\tloss_reg = tf.reduce_sum(tf.sqrt(tf.reduce_sum(self.weight_encoder ** 2, axis = 1)))\n","\t\t\tself.loss_reg = self.reg_lamda * loss_reg\n","\t\t\tself.l2_loss = tf.nn.l2_loss(weight_decoder) * 1E-3\n","\n","\t\t\tself.loss = self.loss_mse + self.loss_reg + self.l2_loss\n","\n","\t\twith tf.name_scope('weight_vector'):\n","\t\t\tself.weight_vector = tf.reduce_sum(self.weight_encoder ** 2, axis = 1)\n","\n","\n","class unbalanced_DAE(object):\n","\n","\t\"\"\"\n","\tAn unbalanced version of DAE. the differences is that a weight pos_weight is added\n","\tto the MSE reconstruction loss for positive examples. For this purpose, the labels\n","\tof the examples are used.\n","\t\"\"\"\n","\n","\tdef __init__(self, n_feature, n_hidden, noise_scale, noise_std,\n","\t             posi_weight = 1.0, reg_lamda = 0.00):\n","\n","\t\tself.n_hidden = n_hidden\n","\t\tself.n_feature = n_feature\n","\t\tself.reg_lamda = reg_lamda\n","\t\tself.noise_scale = noise_scale\n","\t\tself.noise_std = noise_std\n","\t\tself.posi_weight = posi_weight\n","\n","\t\tself.data = tf.placeholder(shape = [None, n_feature], dtype = tf.float64)\n","\t\tself.label = tf.placeholder(shape = [None, 1], dtype = tf.float64)\n","\t\t# self.data = tf.compat.v1.placeholder(shape = [None, n_feature], dtype = tf.float64)\n","\t\t# self.label = tf.compat.v1.placeholder(shape = [None, 1], dtype = tf.float64)\n","\t\t# self.data = tf.random.uniform([None, n_feature], dtype = tf.float64)\n","\t\t# self.label = tf.random.uniform([None, 1], dtype = tf.float64)\n","\t\tself.noise = self.noise_scale * tf.random_normal([n_feature], dtype = tf.float64,\n","\t\t                                                  stddev = self.noise_std)\n","\t\tdata_with_noise = self.data + self.noise\n","\n","\t\tself.weight_encoder = tf.get_variable(name = 'weight_encoder',\n","\t\t\t                    shape = [self.n_feature, self.n_hidden],\n","\t\t\t                    dtype = tf.float64)\n","\t\tself.bias_encoder = tf.Variable(tf.zeros([self.n_hidden],\n","\t\t\t                                      dtype = tf.float64),\n","\t\t                                name = 'bias_encoder')\n","\n","\t\tweight_decoder = tf.get_variable(name = 'weight_decoder',\n","\t\t\t                    shape = [self.n_hidden, self.n_feature],\n","\t\t\t                    dtype = tf.float64)\n","\t\tbias_decoder = tf.Variable(tf.zeros([self.n_feature], dtype = tf.float64),\n","\t\t\t                           name = 'bias_decoder')\n","\n","\t\twith tf.name_scope('Encoder'):\n","\t\t\tdata_encoded = tf.add(tf.matmul(data_with_noise, self.weight_encoder),\n","\t\t\t\t                  self.bias_encoder)\n","\t\t\tdata_encoded = tf.nn.sigmoid(data_encoded)\n","\n","\t\twith tf.name_scope('Decoder'):\n","\t\t\tdata_recons = tf.add(tf.matmul(data_encoded, weight_decoder),\n","\t\t\t\t                 bias_decoder)\n","\t\t\tself.data_recons = tf.nn.sigmoid(data_recons)\n","\n","\t\twith tf.name_scope('Loss'):\n","\t\t\tdiff = self.data_recons - self.data\n","\t\t\tweights = self.label * (posi_weight -1) + 1\n","\t\t\tweights = tf.reshape(weights, shape = [-1])\n","\t\t\tself.loss_mse = 0.5 * tf.reduce_mean(tf.reduce_sum(diff**2, axis = 1) * weights)\n","\t\t\tloss_reg = tf.reduce_sum(tf.sqrt(tf.reduce_sum(self.weight_encoder ** 2, axis = 1)))\n","\t\t\tself.loss_reg = self.reg_lamda * loss_reg\n","\t\t\tself.l2_loss = tf.nn.l2_loss(weight_decoder) * 1E-3\n","\n","\t\t\tself.loss = self.loss_mse + self.loss_reg + self.l2_loss\n","\n","\t\twith tf.name_scope('weight_vector'):\n","\t\t\tself.weight_vector = tf.reduce_sum(self.weight_encoder ** 2, axis = 1)"],"metadata":{"id":"e3ojKl28b2pC","executionInfo":{"status":"ok","timestamp":1720213818154,"user_tz":420,"elapsed":209,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","def P_R_F1(confusion_matrix):\n","\n","    category = confusion_matrix.shape[0]\n","    precision = []\n","    recall = []\n","    f1 = []\n","    for i in range (category):\n","        TP = confusion_matrix[i,i]\n","\n","        precsion_temp = TP/np.sum(confusion_matrix[:,i])\n","        recall_temp = TP/np.sum(confusion_matrix[i,:])\n","        f1_temp = 2*precsion_temp*recall_temp/(precsion_temp + recall_temp)\n","\n","        precision.append(precsion_temp)\n","        recall.append(recall_temp)\n","        f1.append(f1_temp)\n","\n","    return precision, recall, f1\n","\n","# shaping labels to one-hot vectors for trainning\n","def label_coding(label, batch_size, category):\n","    new_label = tf.cast(label, dtype = tf.int32)\n","    new_label = tf.reshape(new_label, [batch_size, 1])\n","    new_label = tf.one_hot(new_label, depth = category)\n","    return tf.reshape(new_label, [batch_size, category])\n","\n","# get next batch of data and label\n","def next_batch(filename, batch_size, conf, buffer_size = 0):\n","\n","    len_feature = conf.len_feature\n","    len_label = conf.len_label\n","    num_classes = conf.num_classes\n","    one_hot_encoding = conf.one_hot_encoding\n","\n","    def read_data(examples):\n","        features = {\"features\": tf.FixedLenFeature([len_feature], tf.float32),\n","                    \"label_2\": tf.FixedLenFeature([len_label], tf.float32),\n","                    \"label_10\": tf.FixedLenFeature([len_label], tf.float32)}\n","        parsed_features = tf.parse_single_example(examples, features)\n","        return parsed_features['features'], parsed_features['label_2'], \\\n","               parsed_features['label_10']\n","\n","    data = tf.data.TFRecordDataset(filename)\n","    data = data.map(read_data)\n","    if buffer_size != 0:\n","        data = data.shuffle(buffer_size = buffer_size)\n","    data = data.repeat()\n","    data = data.batch(batch_size)\n","    iterator = data.make_one_shot_iterator()\n","    next_data, next_label_2, next_label_10 = iterator.get_next()\n","\n","    if one_hot_encoding == True:\n","        if num_classes == 2:\n","            next_label_2 = label_coding(next_label_2, batch_size,\n","                                        num_classes)\n","        else:\n","            next_label_10 = label_coding(next_label_10, batch_size,\n","                                         num_classes)\n","\n","    return next_data, next_label_2, next_label_10\n","\n","\n","def trans_dataset(file_tfr, file_txt, num_examples, num_classes):\n","    # with tf.Session() as sess:\n","    all_data, all_label = next_batch(file_tfr, num_examples)\n","    all_label = label_coding(all_label, num_examples, num_classes)\n","\n","    # record = np.concatenate([sess.run(all_data), sess.run(all_label)], axis = 1)\n","    record = np.concatenate([all_data, all_label], axis = 1)\n","    np.savetxt(file_txt, record, fmt = '%.6e')\n","\n","def split_dataset(file_train, file_test, k, file_folder_new): # k is refer to k_fold\n","\n","    trainset = np.loadtxt(file_train)\n","    testset = np.loadtxt(file_test)\n","    dataset = np.concatenate((trainset, testset))\n","\n","    for i in range(k - 1):\n","        trainset, testset = train_test_split(dataset, test_size = 1/(k - i))\n","        dataset = trainset\n","        np.savetxt(file_folder_new + str(i) + '.txt', testset)\n","\n","    np.savetxt(file_folder_new + str(k - 1) + '.txt', trainset)\n","\n","def get_dataset(file_folder, index_test, indices_train):\n","\n","    testset = np.loadtxt(file_folder + str(index_test) + '.txt')\n","\n","    count = 0\n","    for other in indices_train:\n","        temp = np.loadtxt(file_folder + str(other) + '.txt')\n","\n","        if count == 0:\n","            trainset = temp\n","        else:\n","            trainset = np.concatenate((trainset, temp))\n","\n","        count += 1\n","\n","    return trainset, testset\n","\n","def parse_pos_neg(dataset):\n","\n","    label = dataset[:, -1]\n","\n","    record_posi = []\n","    record_neg = []\n","\n","    records_len = dataset.shape[-1]\n","    records_num = dataset.shape[0]\n","\n","    for index in range(records_num):\n","        record = dataset[index, :]\n","        record = np.reshape(record, (1, records_len))\n","        if label[index] == 0.:\n","            record_posi.append(record)\n","        else:\n","            record_neg.append(record)\n","\n","    posi = np.concatenate(record_posi)\n","    neg = np.concatenate(record_neg)\n","\n","    return posi, neg\n","\n","\"\"\"\n","if __name__ == '__main__':\n","\n","    num_train = 125973\n","    num_test = 22543\n","    file_folder = 'normalized/'\n","\n","    num_classes = 2\n","    trans_dataset(file_folder + 'train+.tfrecords', file_folder + 'train2.txt', num_train, num_classes)\n","    trans_dataset(file_folder + 'test+.tfrecords', file_folder + 'test2.txt', num_test, num_classes)\n","\n","    num_classes = 5\n","    trans_dataset(file_folder + 'train5.tfrecords', file_folder + 'train5.txt', num_train, num_classes)\n","    trans_dataset(file_folder + 'test5.tfrecords', file_folder + 'test5.txt', num_test, num_classes)\n","\n","    file_folder_new = file_folder + 'cross_validation_5/'\n","\n","    file_train = file_folder + 'train5.txt'\n","    file_test = file_folder +'test5.txt'\n","    split_dataset(file_train, file_test, k =10, file_folder_new = file_folder_new)\n","\n","    dataset = np.loadtxt(file_folder +'train_new.txt')\n","    #dataset = [file_folder + str(x + 1) + '_train.csv' for x in range(4)]\n","    posi, neg = parse_pos_neg(dataset)\n","\n","    np.savetxt(file_folder + 'train_posi.txt',posi )\n","    np.savetxt(file_folder + 'train_neg.txt', neg)\n","    \"\"\""],"metadata":{"id":"Yj16BTI6b75X","colab":{"base_uri":"https://localhost:8080/","height":192},"executionInfo":{"status":"ok","timestamp":1720213824343,"user_tz":420,"elapsed":232,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"cc6c73da-4342-415a-8b60-fca0e842591d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nif __name__ == '__main__':\\n\\n    num_train = 125973\\n    num_test = 22543\\n    file_folder = 'normalized/'\\n\\n    num_classes = 2\\n    trans_dataset(file_folder + 'train+.tfrecords', file_folder + 'train2.txt', num_train, num_classes)\\n    trans_dataset(file_folder + 'test+.tfrecords', file_folder + 'test2.txt', num_test, num_classes)\\n\\n    num_classes = 5\\n    trans_dataset(file_folder + 'train5.tfrecords', file_folder + 'train5.txt', num_train, num_classes)\\n    trans_dataset(file_folder + 'test5.tfrecords', file_folder + 'test5.txt', num_test, num_classes)\\n\\n    file_folder_new = file_folder + 'cross_validation_5/'\\n\\n    file_train = file_folder + 'train5.txt'\\n    file_test = file_folder +'test5.txt'\\n    split_dataset(file_train, file_test, k =10, file_folder_new = file_folder_new)\\n\\n    dataset = np.loadtxt(file_folder +'train_new.txt')\\n    #dataset = [file_folder + str(x + 1) + '_train.csv' for x in range(4)]\\n    posi, neg = parse_pos_neg(dataset)\\n\\n    np.savetxt(file_folder + 'train_posi.txt',posi )\\n    np.savetxt(file_folder + 'train_neg.txt', neg)\\n    \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import time\n","# import tensorflow as tf\n","import tensorflow.compat.v1 as tf\n","import numpy as np\n","#from autoencoders import DAE, unbalanced_DAE\n","#from utils import next_batch, P_R_F1\n","\n","tf.disable_v2_behavior()\n","tf.reset_default_graph()\n","\n","# system parameters\n","\n","class Configures(object):\n","\n","\tdef __init__(self):\n","        # parameter of records\n","\t\tself.len_feature = 202\n","\t\tself.len_label = 1\n","\t\t#self.num_classes = 2\n","\t\tself.num_classes = 10\n","\t\tself.one_hot_encoding = False\n","\t\tself.num_records_train = 1625628\n","\t\tself.num_records_test = 508012\n","\n","        # parameters for training\n","\t\tself.batch_size = 256\n","\t\tself.batch_size_test = 2048\n","\t\tself.training_epochs = 2\n","\t\tself.learn_rate_start = 1E-4\n","\n","\t\tself.batch_train = self.num_records_train//self.batch_size\n","\t\tself.batch_test = self.num_records_test//self.batch_size_test\n","\n","n_hidden = 64\n","noise_scale = 0.\n","noise_std = 0.1\n","conf = Configures()\n","\n","# training op\n","with tf.Session() as sess:\n","\n","\t#AE = DAE(conf.len_feature, n_hidden, noise_scale, noise_std, reg_lamda = 0.001)\n","\tAE = unbalanced_DAE(conf.len_feature, n_hidden, noise_scale, noise_std, posi_weight = 3.5,\n","\t\t                reg_lamda = 0.001)\n","\n","\tglobal_step = tf.Variable(0, name = 'training_steps', trainable = False)\n","\tlearn_rate = tf.train.exponential_decay(conf.learn_rate_start, global_step, 2000, 0.96, staircase=True)\n","\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","\twith tf.control_dependencies(update_ops):\n","\t\toptimizer = tf.train.AdamOptimizer(conf.learn_rate_start)\n","\t\tgrads_and_vars = optimizer.compute_gradients(AE.loss)\n","\t\tgrads_clipped = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in grads_and_vars]\n","\t\ttrain_op = optimizer.apply_gradients(grads_clipped, global_step = global_step)\n","\n","\tsess.run(tf.global_variables_initializer())\n","\n","\t# Reading data\n","\tfile_train = ['/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/normalized/train_202.tfrecords',\n","               '/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/normalized/validation_202.tfrecords']\n","\tfile_test = '/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/normalized/test_202.tfrecords'\n","  # file_train = ['/content/normalized/train.tfrecords', '/content/normalized/validation.tfrecords']\n","\t# file_test = '/content/normalized/test.tfrecords'\n","\ttrain_data, train_label, _ = next_batch(file_train, conf.batch_size, conf, 150)\n","\ttest_data, test_label, _ = next_batch(file_test, conf.batch_size_test, conf)\n","\n","\tmin_loss = 100.\n","\tfor epoch in range(conf.training_epochs):\n","\t\ttime_start = time.time()\n","\t\ttotal_mse_loss = 0.\n","\t\ttotal_loss = 0.\n","\t\ttotal_reg_loss = 0.\n","\n","\t\tfor step in range(conf.batch_train):\n","\t\t\tdata, label = sess.run([train_data, train_label])\n","\n","\t\t\tfeed_dict = {AE.data: data, AE.label: label}\n","\t\t\t_, loss, loss_mse, loss_reg = sess.run([train_op, AE.loss, AE.loss_mse, AE.loss_reg],\n","\t\t\t                                        feed_dict = feed_dict)\n","\n","\t\t\ttotal_loss += loss\n","\t\t\ttotal_mse_loss += loss_mse\n","\t\t\ttotal_reg_loss += loss_reg\n","\n","\t\ttime_train_end = time.time()\n","\t\ttest_loss = 0.\n","\t\ttest_loss_reg = 0.\n","\t\ttest_loss_mse = 0.\n","\n","\t\tfor step in range(conf.batch_test):\n","\t\t\tdata, label = sess.run([test_data, test_label])\n","\n","\t\t\tfeed_dict = {AE.data: data, AE.label: label}\n","\t\t\tweights, loss, loss_mse, loss_reg = sess.run([AE.weight_vector, AE.loss, AE.loss_mse, AE.loss_reg],\n","\t\t\t                                              feed_dict = feed_dict)\n","\t\t\ttest_loss += loss/conf.batch_test\n","\t\t\ttest_loss_mse += loss_mse/conf.batch_test\n","\t\t\ttest_loss_reg += loss_reg/conf.batch_test\n","\n","\t\ttime_test_end = time.time()\n","\n","\t\ttime_duration_train = int(time_train_end - time_start)\n","\t\ttime_duration_test = int(time_test_end - time_train_end)\n","\n","\n","\t\tif test_loss < min_loss:\n","\t\t\tmin_loss = test_loss\n","\n","\t\t\tfile_folder = 'feature_select_AE/'\n","\t\t\tif not os.path.exists(file_folder):\n","\t\t\t\tos.mkdir(file_folder)\n","\n","\t\t\tfile_path = os.path.join(file_folder, 'weights_new_3.5.txt')\n","\t\t\tif not os.path.exists(file_path):\n","\t\t\t\twith open(file_path, 'x'):\n","\t\t\t\t\tpass  # Just create the file and do nothing else\n","\n","\t\t\tnp.savetxt('/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/feature_select_AE/weights_new_3.5.txt', weights, fmt = \"%.6E\")\n","\n","\t\tprint(\"Epoch:\", \"%d,\" % (epoch + 1),\n","\t\t\t  \"Loss on Train:\", \"{:.6f}\".format(total_loss/(conf.batch_train)),\n","\t\t\t  \"mse on Train:\", \"{:.6f}\".format(total_mse_loss/conf.batch_train),\n","\t\t\t  \"reg on Train:\", \"{:.6f}\".format(total_reg_loss/conf.batch_train),\n","\t\t\t  \"Loss on Test:\", \"{:.6f}\".format(test_loss),\n","\t\t\t  \"mse on Test:\", \"{:.6f}\".format(test_loss_mse),\n","\t\t\t  \"reg on Test:\", \"{:.6f}\".format(test_loss_reg))\n","\n","\t\tprint(time_duration_train)\n","\t\tprint(time_duration_test)"],"metadata":{"id":"NK241BlVcBP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720214279327,"user_tz":420,"elapsed":437484,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"5d0085ec-7a46-4799-ed69-97a4a13c3b06"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","WARNING:tensorflow:From <ipython-input-10-8ccfd04d9eb6>:53: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss on Train: 26.172168 mse on Train: 25.978852 reg on Train: 0.076266 Loss on Test: 22.523709 mse on Test: 22.248283 reg on Test: 0.090094\n","179\n","32\n","Epoch: 2, Loss on Train: 21.649145 mse on Train: 21.313077 reg on Train: 0.099512 Loss on Test: 21.681828 mse on Test: 21.296292 reg on Test: 0.106025\n","188\n","35\n"]}]},{"cell_type":"code","source":["import heapq\n","import os\n","import re\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# import tensorflow as tf\n","import tensorflow.compat.v1 as tf\n","from pandas import read_csv\n","\n","tf.disable_v2_behavior()\n","\n","def get_indices(num_select, num_feature, file_weights):\n","\t\"\"\"\n","\tThis function is to select maximum k features according to their\n","\tweights.\n","\n","\tPram:\n","\t\tnum_select: An interger, the number of the selected features\n","\t\tnum_feature: An interger, the number of the original features\n","\t\tfile_weights: A txt file storing a numpy array. Each row of the\n","\t\t              array is the weight for a feature\n","\tReturn:\n","\t\ta list containing the indices of selected features\n","\t\"\"\"\n","\n","\tx = np.arange(1, num_feature + 1)\n","\ty = np.loadtxt(file_weights)\n","\tindices = heapq.nlargest(num_select, range(len(y)), y.take)\n","\tplt.scatter(x, y)\n","\tplt.show()\n","\tplt.savefig('weights_dis.eps', format = 'eps')\n","\t# print(indices)\n","\n","\tlargest_values = [y[i] for i in indices]\n","\tprint(\"Indices of selected features:\", indices)\n","\tprint(\"Values of selected features:\", largest_values)\n","\n","\treturn indices\n","\n","\n","def read_data(examples):\n","    features = {\"features\": tf.FixedLenFeature([num_feature], tf.float32),\n","                \"label_2\": tf.FixedLenFeature([len_label], tf.float32),\n","                \"label_10\": tf.FixedLenFeature([len_label], tf.float32)}\n","    parsed_features = tf.parse_single_example(examples, features)\n","    return parsed_features['features'], parsed_features['label_2'], \\\n","           parsed_features['label_10']\n","\n","\n","# get next batch of data and label\n","def next_batch(filename, num_examples):\n","\n","    data = tf.data.TFRecordDataset(filename)\n","    data = data.map(read_data)\n","    data = data.batch(num_examples)\n","    iterator = data.make_one_shot_iterator()\n","    next_data, next_label_2, next_label_10 = iterator.get_next()\n","    return next_data, next_label_2, next_label_10\n","\n","\n","def make_tfrecords(dataset, file_to_save):\n","\t[features, label_2, label_10] = dataset\n","\n","\twith tf.python_io.TFRecordWriter(file_to_save) as writer:\n","\t\tfor index in range(features.shape[0]):\n","\t\t\tfeature = {'features': tf.train.Feature(float_list = tf.train.FloatList(value = features[index, :])),\n","\t\t\t           'label_2': tf.train.Feature(float_list = tf.train.FloatList(value = label_2[index, :])),\n","\t\t\t           'label_10': tf.train.Feature(float_list = tf.train.FloatList(value = label_10[index, :]))}\n","\t\t\texample = tf.train.Example(features = tf.train.Features(feature = feature))\n","\t\t\twriter.write(example.SerializeToString())\n","\n","\n","def selection(data, indices):\n","\t\"\"\"\n","\tselect the columns (indicating the features) according to the indices\n","\t\"\"\"\n","\n","\treturn data[:, indices]\n","\n","\n","def select_feature(file, num_examples, indices):\n","\t\"\"\"\n","\tThe main function of feature selection.\n","\n","\tParams:\n","\t  file: The .tfrecords file containing original data.tfrecords\n","\t  num_examples: The number of examples in the file\n","\t  indices: The indices of features to be selected\n","\n","\tReturn:\n","\t  None\n","\t  In the function, a new .tfrecords file with tail of 'selected'\n","\t  will be created in the same folder with the original data\n","\t\"\"\"\n","\n","\twith tf.Session() as sess:\n","\t\tdata, label_2, label_10 = sess.run(next_batch(file, num_examples))\n","\n","\tdata_select = selection(data, indices)\n","\n","\tfile_name = file.split('\\\\')[-1]\n","\tfile_tail = len('.tfrecords')\n","\tfile_to_save = file_name[:-1*file_tail] + '_select_' + str(len(indices)) + '.tfrecords'\n","\n","\n","\tmake_tfrecords([data_select, label_2, label_10], file_to_save)\n","\n","\n","def show_feature_name(indices):\n","\t\"\"\"\n","\tThe function to convert indices to feature names\n","\n","\tParams:\n","\t  indices:the indices of the features\n","\tReturn:\n","\t  None.\n","\t  The name of features will be print\n","\t\"\"\"\n","\n","\t#dirname = os.path.dirname(os.getcwd())\n","\t#file = os.path.join(dirname, 'normalized/', '1_test.csv')\n","\tfile = os.path.join( '/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/normalized/', '1_test.csv')\n","\t# file = os.path.join( 'normalized/', '1_test.csv')\n","\tdata = read_csv(file, index_col = 0)\n","\tcols = data.columns\n","\n","\tfor x in indices:\n","\t\tprint(cols[x])\n","\n","\n","if __name__ == '__main__':\n","\n","\tnum_select = 12   #The number of selected features\n","\tnum_feature = 202\n","\tlen_label = 1\n","\tfile_weights = '/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/feature_select_AE/weights_new_3.5.txt'\n","\t# file_weights = 'feature_select_AE/weights_new_3.5.txt'\n","\n","\tindices = get_indices(num_select, num_feature, file_weights)\n","\t#print(indices)\n","\tshow_feature_name(indices)\n","\n","\tdirname = os.path.dirname(os.getcwd())\n","\t# file_folder = os.path.join(dirname, '/content/', 'normalized/')\n","\tfile_folder = \"/content/drive/MyDrive/Colab Notebooks/UNSW-NB15 - CSV Files/normalized/\"\n","\n","\tfile_train = file_folder + 'train_202.tfrecords'\n","\tfile_valid = file_folder + 'validation_202.tfrecords'\n","\tnum_examples_train = 1778030\n","\tnum_examples_validation = 254005\n","\n","\tfile_test = file_folder + 'test_202.tfrecords'\n","\tnum_examples_test = 508012\n","\n","\tselect_feature(file_train, num_examples_train, indices)\n","\tselect_feature(file_valid, num_examples_validation, indices)\n","\tselect_feature(file_test, num_examples_test, indices)"],"metadata":{"id":"mD_WhtZDcJMn","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1720217030384,"user_tz":420,"elapsed":102127,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"a91627de-83cc-4e4c-ae0c-d85d0dcb8930"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtrElEQVR4nO3df3TU9Z3v8dckQsKPZGiAZCY1YKD+aBqlhZU0R9fdaoBwPYjV7rYUjj/qaptCt4ptOXhWke6exeo9tteWwp499UcPW+16T4XFtvTwQ2DVCBXMtWlaLmSjoExgDTczAUyAzOf+EWdkkkkyk8x85/vj+Thnjmbmm5nPl2/y/b7y+Xw/74/PGGMEAABgkbxcNwAAAHgL4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYKlLct2A/qLRqI4fP66ioiL5fL5cNwcAAKTAGKOuri6Vl5crL2/ovg3bhY/jx4+roqIi180AAAAjcOzYMV166aVDbmO78FFUVCSpr/HFxcU5bg0AAEhFJBJRRUVF/Do+FNuFj9hQS3FxMeEDAACHSeWWCW44BQAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsZbsiY27SGzXa33ZKJ7u6VVpUqLmVJcrPY70aAIC3ET6yZFtzSGu3tigU7o4/F/QXas2iKtVXB3PYMgAAcothlyzY1hxSw6aDCcFDktrD3WrYdFDbmkM5ahkAALlH+Miw3qjR2q0tMkleiz23dmuLeqPJtgAAwP0IHxm2v+3UgB6PixlJoXC39redsq5RAADYCOEjw052DR48RrIdAABuQ/jIsNKiwoxuBwCA2xA+MmxuZYmC/kINNqHWp75ZL3MrS6xsFgAAtkH4yLD8PJ/WLKqSpAEBJPb1mkVV1PsAAHgW4SML6quD2rBstgL+xKGVgL9QG5bNps4HAMDTKDKWJfXVQc2rClDhFACAfggfWZSf51PtzMm5bgYAALaS1rDLunXrdO2116qoqEilpaW69dZbdejQoYRturu7tXz5ck2ePFkTJ07U7bffrhMnTmS00U7TGzVqbO3Qlqb31djaQYExAICnpdXzsWfPHi1fvlzXXnutLly4oIceekjz589XS0uLJkyYIEl64IEH9Otf/1ovvvii/H6/VqxYodtuu02vvfZaVnbA7ljjBQCARD5jzIj/DP/v//5vlZaWas+ePbrhhhsUDoc1depU/eIXv9CXvvQlSdKf//xnffrTn1ZjY6M+//nPD/uekUhEfr9f4XBYxcXFI22aLcTWeOn/Dxy764ObTwEAbpHO9XtUs13C4bAkqaSkr2bFgQMHdP78edXV1cW3ueqqqzRt2jQ1NjYmfY+enh5FIpGEhxuwxgsAAMmNOHxEo1Hdf//9uu6661RdXS1Jam9v19ixYzVp0qSEbcvKytTe3p70fdatWye/3x9/VFRUjLRJtsIaLwAAJDfi8LF8+XI1NzfrhRdeGFUDVq9erXA4HH8cO3ZsVO9nF6zxAgBAciOaartixQq9/PLL2rt3ry699NL484FAQOfOnVNnZ2dC78eJEycUCASSvldBQYEKCgpG0gxbY40XAACSS6vnwxijFStW6KWXXtKuXbtUWVmZ8PqcOXM0ZswY7dy5M/7coUOHdPToUdXW1mamxQ7BGi8AACSXVs/H8uXL9Ytf/EJbtmxRUVFR/D4Ov9+vcePGye/365577tHKlStVUlKi4uJifetb31JtbW1KM13cJLbGS8Omg/JJCTeessYLAMDL0ppq6/Mlv1A+88wzuuuuuyT1FRl78MEH9fzzz6unp0cLFizQT3/600GHXfpz01RbiTofAABvSOf6Pao6H9ngtvAh9U27ZY0XAICbpXP9Zm0XC7DGCwAAHxtVkTEAAIB0ET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLXZLrBgAAYKXeqNH+tlM62dWt0qJCza0sUX6eL9fN8hTCBwDAM7Y1h7R2a4tC4e74c0F/odYsqlJ9dTCHLfMWhl0AAJ6wrTmkhk0HE4KHJLWHu9Ww6aC2NYdy1DLvIXwAAFyvN2q0dmuLTJLXYs+t3dqi3miyLZBphA8AgOvtbzs1oMfjYkZSKNyt/W2nrGuUhxE+AACud7Jr8OAxku0wOoQPAIDrlRYVZnQ7jA7hAwDgenMrSxT0F2qwCbU+9c16mVtZYmWzPIvwAQBwvfw8n9YsqpKkAQEk9vWaRVXU+7AI4QMA4An11UFtWDZbAX/i0ErAX6gNy2ZT58NCFBkDAHhGfXVQ86oCVDjNMcIHAMBT8vN8qp05OdfN8DSGXQAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAAS6UdPvbu3atFixapvLxcPp9PmzdvTnj9rrvuks/nS3jU19dnqr0AAMDh0g4fZ86c0axZs7R+/fpBt6mvr1coFIo/nn/++VE1EgAAuEfa5dUXLlyohQsXDrlNQUGBAoHAiBsFAADcKyv3fOzevVulpaW68sor1dDQoI6OjkG37enpUSQSSXgAAAD3ynj4qK+v189//nPt3LlTP/jBD7Rnzx4tXLhQvb29Sbdft26d/H5//FFRUZHpJgEAABvxGWPMiL/Z59NLL72kW2+9ddBt/uu//kszZ87Ujh07dNNNNw14vaenRz09PfGvI5GIKioqFA6HVVxcPNKmAQAAC0UiEfn9/pSu31mfajtjxgxNmTJFR44cSfp6QUGBiouLEx4AAMC9sh4+3nvvPXV0dCgYDGb7owAAgAOkPdvl9OnTCb0YbW1tampqUklJiUpKSrR27VrdfvvtCgQCam1t1fe+9z196lOf0oIFCzLacAAA4Exph48333xTX/jCF+Jfr1y5UpJ05513asOGDXr77bf13HPPqbOzU+Xl5Zo/f77+8R//UQUFBZlrNQAAcKxR3XCaDencsAIAAOzBVjecAgAAXIzwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUmnX+fC63qjR/rZTOtnVrdKiQs2tLFF+ni/XzQIAwDEIH2nY1hzS2q0tCoW7488F/YVas6hK9dWUjwcAIBUMu6RoW3NIDZsOJgQPSWoPd6th00Ftaw7lqGUAADgL4SMFvVGjtVtblKwUbOy5tVtb1Bu1VbFYAABsifCRgv1tpwb0eFzMSAqFu7W/7ZR1jQIAwKEIHyk42TV48BjJdgAAeBnhIwWlRYUZ3Q4AAC9jtksK5laWKOgvVHu4O+l9Hz5JAX/ftFsAgLNQQsF6hI8U5Of5tGZRlRo2HZRPSgggsR/PNYuq+GEFAIehhEJuMOySovrqoDYsm62AP3FoJeAv1IZls/khBQCHoYRC7tDzkYb66qDmVQXongMAhxuuhIJPfSUU5lUFOMdnAeEjTfl5PtXOnJzrZgAARiGdEgqc8zOPYRcAgOdQQiG3CB8AAM+hhEJuET4AAJ4TK6Ew2N0cPvXNeqGEQnYQPgAAnhMroSBpQAChhEL2ET4AAJ5ECYXcYbYLAMCzKKGQG4QPAICnUULBegy7AAAAS9HzYTEWMAIAeB3hw0IsYAQAAMMulmEBIwAA+hA+LDDcAkZS3wJGvdFkWwAA4C6EDwuks4ARAABuR/iwQKoLE21vac9ySwAAyD3ChwVSXZjo6dfe4d4PAIDrET4sEFvAaDg+ce8HAMD9CB8WuHgBo6Fw7wcAwAsIHxaprw7qnusuS2nbVO8RAQDAiQgfFqqrCqS0Xar3iAAA4ESEDwvF7v0YrJi6T30VT+dWlljZLAAALEX4sNDF9370DyCxr9csqmKtFwCAqxE+LFZfHdSGZbMV6Df7JeAv1IZls1njBQDgeiwslwP11UHNqwqwui0AwJMIHzmSn+dT7czJuW4GAACWY9gFAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsNQluW6AHfRGjfa3ndLJrm6VFhVqbmWJ8vN8uW4WAACu5Pnwsa05pLVbWxQKd8efC/oLtWZRleqrgzlsGQAA7uTpYZdtzSE1bDqYEDwkqT3crYZNB7WtORR/rjdq1NjaoS1N76uxtUO9UZORNmTrfQEAsCvP9nz0Ro3Wbm1Rsku9keSTtHZri+ZVBbS9pT0rvSP0ugAAvMizPR/7204N6PG4mJEUCnfrJ7uOpNw7ko50el0AAHATz4aPk12DB4+LPfNa26C9I1Jf70i6QyXD9bqM9H0BAHACz4aP0qLClLbr/PD8oK/Fekf2t51K67NT7XVJ930BAHACz4aPuZUlCvoLNdiEWp+kSePGpPReqfaipLt9uu8LAIATeDZ85Of5tGZRlSQNCCCxr+++7rKU3ivVXpR0t0/3fQEAcALPhg9Jqq8OasOy2Qr4Ey/yAX+hNiybrRU3Xj5s70jQ31eULB2p9LqM5H0BAHACz061jamvDmpeVWDQCqdrFlWpYdNB+aSEG0RjwWHNoqq0q6HGel0y/b4AADiBzxhjqykVkUhEfr9f4XBYxcXFuW6OpOzV46DOBwDALdK5fhM+UpSt9V9YVwYA4AbpXL/Tvudj7969WrRokcrLy+Xz+bR58+aE140xeuSRRxQMBjVu3DjV1dXp8OHD6X6M7eTn+VQ7c7IWf/aTqp05OWMBIVvvCwCAXaUdPs6cOaNZs2Zp/fr1SV9//PHH9dRTT2njxo3at2+fJkyYoAULFqi7m2mjAABgBDecLly4UAsXLkz6mjFGP/rRj/QP//APWrx4sSTp5z//ucrKyrR582Z95StfGV1rAQCA42V0qm1bW5va29tVV1cXf87v96umpkaNjY1Jv6enp0eRSCThAQAA3Cuj4aO9vV2SVFZWlvB8WVlZ/LX+1q1bJ7/fH39UVFRkskkAAMBmcl5kbPXq1QqHw/HHsWPHct0kAACQRRkNH4FAQJJ04sSJhOdPnDgRf62/goICFRcXJzwAAIB7ZTR8VFZWKhAIaOfOnfHnIpGI9u3bp9ra2kx+FAAAcKi0Z7ucPn1aR44ciX/d1tampqYmlZSUaNq0abr//vv1T//0T7r88stVWVmphx9+WOXl5br11lsz2W4AAOBQaYePN998U1/4whfiX69cuVKSdOedd+rZZ5/V9773PZ05c0b33XefOjs7df3112vbtm0qLGSFVgAAQHl1AACQAVktrw4AADAahA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJZKu84HnK83arS/7ZROdnWrtKhQcytLlJ/ny3WzAAAeQfjwmG3NIa3d2qJQuDv+XNBfqDWLqlRfHcxhywAAXsGwi4dsaw6pYdPBhOAhSe3hbjVsOqhtzaEctQwA4CWED4/ojRqt3dqiZOVsY8+t3dqi3qitCt4CAFyI8OER+9tODejxuJiRFAp3a3/bKesaBQDwJMKHR5zsGjx4jGQ7AABGihtObSyTs1JKi1JbVTjV7QAAGCnCh01lelbK3MoSBf2Fag93J73vwycp4O8LOAAAZBPDLjaUjVkp+Xk+rVlUJakvaFws9vWaRVXU+wAAZB3hw2ayOSulvjqoDctmK+BPHFoJ+Au1Ydls6nwAACzBsIvNpDMrpXbm5LTfv746qHlVASqcAgByhvBhM1bMSsnP840ouAAAkAkMu9gMs1IAAG5Hz8cIZWtxtkzNSmHxOACAXRE+RiCbi7PFZqU0bDoon5QQQFKdlcLicQAAO2PYJU1WLM42mlkpLB4HALA7nzHGViuJRSIR+f1+hcNhFRcX57o5CXqjRtf/YNegs1FiQyKvrroxI0Mc6Q6dWN0+AABi0rl+M+yShmxPg+0v3VkpVrcPAICRYNglDXZfnM3u7QMAQKLnI6nBhjvsPg3W7u0DAEAifAww1EyReVUBWy/OxuJxAAAnYNjlIsPNFNne0m7rxdlYPA4A4ASEj4+kuqDbvKqArRdnY/E4AIDdMezykXRmith9cTa7tw8A4G2Ej4+kO1PE7ouz2b19AADvYtjlI8wUAQDAGoSPj8Rmigw2MOFT36wXZooAADA6hI+PMFMEAABrED4uwkwRAIDUNwOysbVDW5reV2Nrh3qjtloGzfG44bQfZooAgLcNVWySP0Izg1VtAQD4SKzYZP8LY+zPT3rBB5fO9ZthFwAAlHqxSYZgRo/wAQCA0is2idEhfAAAoPSLTWLkCB8AAIhik1ZitgsAAPq42GR7uDvpfR8+9ZVeyFSxyd6o8ezMSsIHAAD6uNhkw6aD8kkJASTTxSa9Pp2XYRcAAD5iRbHJ2HTe/je3toe71bDpoLY1h0b9GXZHzwcAABfJZrHJ4abz+tQ3nXdeVcDVQzCEDwAA+snP86l25uSMv28603mz8fl2wbALAAAWYTpvH8IHAAAWYTpvH8IHAAAWiU3nHexuDp/6Zr1kajqvXRE+AACwSGw6r6QBASTT03ntjPDhAL1Ro8bWDm1pel+NrR0sagQADmbFdF67Y7aLzXm9EA0AuFE2p/M6gc8YY6s/oyORiPx+v8LhsIqLi3PdnJyKFaLpf4BiP5peScgAAPtL5/rNsItNDVeIRuorRMMQDADAaQgfNpVOIRoAAJyE8GFTFKIBALgV4cOmKEQDAHArwodNUYgGAOBWhA+bohANAMCtCB82RiEaAIAbUWTM5rxeiAYA4D6EDwfIz/OpdubkXDcDAICMYNgFAABYivABAAAsxbALAMASvVHD/WuQRPgAAFiAFbpxMYZdsqA3atTY2qEtTe+rsbWDxd8AeFpshe7+61W1h7vVsOmgtjWHctQy5Ao9HxnmtnRPNymA0RhuhW6f+lbonlcV4NziIYSPDIql+/6/ZLF077TCYG4LUgCsl84K3ZQU8A6GXTJkuHQv9aV7pwzB0E0KIBNYoRvJZDx8PProo/L5fAmPq666KtMfYzvppHu7c1uQApA7rNCNZLIy7PKZz3xGO3bs+PhDLnH/6I6b0j3dpAAyJbZCd3u4O+kfND71rVfFCt3ekpVhl0suuUSBQCD+mDJlSjY+xlbclO53tLSntJ0TghSA3GKFbiSTlfBx+PBhlZeXa8aMGVq6dKmOHj066LY9PT2KRCIJDyeKpfvBfn186rtZ0+7pfltzSD977Z2UtnVCkAKQe6zQjf58xpiMDtz/9re/1enTp3XllVcqFApp7dq1ev/999Xc3KyioqIB2z/66KNau3btgOfD4bCKi4sz2bSs+83bIX3zFwcHPB8LJHb/JeuNGl332C61R4bu0Yh1k7666kb+WgGQMqbuu1skEpHf70/p+p3x8NFfZ2enpk+frieffFL33HPPgNd7enrU09MT/zoSiaiioiIn4WM0vxjJpqXGOGV66v/a8X/1wx2HU9p2o82DFADAWumEj6zfCTpp0iRdccUVOnLkSNLXCwoKVFBQkO1mDGs0NS0Gq+8R8/DNn7b9hXpbcyjl4PG16y6z/f4AAOwr63U+Tp8+rdbWVgWD9r1YjaamxbkLUT30UvOgwcMn6R9//SdbT0uNTa1N1byqQBZbAwBwu4yHj+985zvas2eP3nnnHb3++uv64he/qPz8fC1ZsiTTH5URo6lpsa05pM+v26FTZ84N+v5OqO8x3NTaiznhplkAgL1lfNjlvffe05IlS9TR0aGpU6fq+uuv1xtvvKGpU6dm+qMyYqQ1LYYbaunPztNS02kbU+IAAKOV8fDxwgsvZPots2okxcGG6i0ZjJ2npabatgfqruBeDwDAqHl+bZeRFAdLZ5jCCfU9hqtRIkmB4gKtuPFTlrUJAOBeng8fIykOlu4Qit2HKoarQOiT9Ogtn7H1PgAAnMPz4WMkpX9T7S2ZPGGsLQqL9UaNGls7tKXpfTW2diS9eTaVCoSpvA8AAMPJepGxdKVTpCST0qnz0Rs1uv4HuwZdKEmSSiaM0Rur6zT2ktzmu3TrlwxWaG00dVAAAO5nqwqn6cpV+JDSq3Aam+0iKSGA2KmU+mAzctJtY6beBwDgXulcvz0/7HKx/DyfamdO1uLPflK1MycPeY+D3RdKGk39kmy8DwAgNV4Y4s56eXU3q68Oal5VwJYLJY20fkm23gcAMDyvDHETPkYp1ltiNyOpX5LN9wEADG2wIe7YUh926FXPFIZdXGok9Uuy+T4AgMF5bYib8OFSI6lfks33AQAMLp0hbjcgfLjUSOqXZPN9AACD89oQN+HDxTI1I8fuM3sAwOm8NsTNDacul6kZOXae2QMAThcb4h6seKVPfX/wuWWIm/DhAZmakWPXmT0A4HSxIe6GTQflU/LilW4a4mbYBQCQNi8UwrKal4a46fnwsHTKyQNAjFcKYeWCV4a4WdvFozh5ABgJ1nrCYFjbBUOKnTz6zymPVdHb1hzKUcsA2JnXCmEhewgfHsPJA8BIea0QFrKH8OExnDwAjJTXCmEhewgfHsPJA8BIea0QFrKH2S4ek4mTB7NkAG/yWiEsZA/hYwhuvMiO9uTBLBnAu7xWCAvZw1TbQbj5Ihub7SIlP3kMNlWOKXYAJHefHzFy6Vy/CR9JeOEim+7JozdqdP0Pdg16s2qsx+TVVTfyVw/gAW7sGU7GK/uZCelcvxl26We4qag+9U1FnVcVcPQPYLpV9NKZJcP6L4D7eWGtJ3p4sofZLv14aSpq7OSx+LOfVO3MyUOGKWbJAPASijFmF+GjH69eZIdbJIopdgC8gmKM2cewSz9evMim0rXIFDsAXsEwc/bR89FP7CI72ACET30XZrdcZFPtWoxNsZM04N+GKXYA3MSrPeBWInz046WLbLpdi/XVQW1YNlsBf2KvT8Bf6IoZQAAgebMH3GoMuyQRu8j2H4oIuOwu55F0LaY7SwYAnIZh5uwjfAzCCxfZkXYtemGKHQDvopJr9hE+huD2iyxdiwCQnFd6wHOF8GFDVlXUo2sRAAbnhR7wXCF82IyVFfXoWgSAobm9BzxXmO1iI7moqMcMFgCA1ej5sIlcrilD1yIAwEqED5vIdUU9uhYBAFZh2MUmqKgHAPAKwodNTJlYkNJ2THsFADgdwy42sK05pEf/449DbsO0VwCAWxA+ciw2w2WohZmZ9goAcBPCRw4NNcPlYlTUAwC4CeEjh4ab4RLzP780S9ddPsWCFgEA7MSqitdWI3zkUKozVz4405PllgAA7MbKitdWY7ZLDrGwGwAgmVxUvLYSPR85lO7CbrHut/bwhzp15pxKJhYoUOyebjgAQG4rXluF8JFD6Szslqz7LcYt3XAAgNxXvLYCwy45lsrCboN1v8WEXNINBwDwRsVrej5sYKiF3VKdjmskPfTSH/Th+ShDMQDgYF64H5DwYRODLeyW6nRcSTp15rwe+GWTJIZiAMAqmZ4Om+79gE5E+LC5kXarxe6Ijg3dAAAyLxvTYdO5H9CpuOfD5kbarRb7YV27tUW90eEGbQAA6crmdNhU7gd0Mno+bC7W/Zbq0MvF3HBHNADYkRXTYYe6H9Dp6PmwuVj322h+1Jx8RzQA2FE602FHI3Y/4OLPflK1Mye7InhIhA9HiHW/Bf0jG4Jx8h3RAGBHXpgOm00MuzjExd1v7eEP9dqRD/S/D74/5Pe44Y5oALAjL0yHzSbPhg8nrhQY637rjRo9/rtDKX2P0++IBgA78sJ02GzyTPi4OGy888FZPb//qNojzlwpMNXaH/fXXeGI/QEAp/HCdNhs8kT4GGpdlBgn1cVIdQzxsinjs9wSAPCu2P14/a8vAQf9MZsrrg8fsXnYqZQnd8pKgYw1AoA9uHk6bDa5Onykui5KjFPqYjDWCAD2MdjyGBicq6faprMuysXsPjUqNtYoaUD9D8YaAQB25+rwMdIQ4YThCreX3gUAuJerh11GEiKCDhquYKwRAOBErg4fI1kXxWnDFYw1AgCcxtXDLhffGzGcPJ/0068yXAEAQLa5OnxIfUMTG5fN1qTxY4bc7idLPqf/cQ3BAwCs1Bs1amzt0Jam99XY2qHeaKrzE+3NrfuVKa4edomJ3Rvxk11H9Mxrber88Hz8NSdVNk3FUGXjM11SPvZ+7eEPderMOZVMLFDpxALJJ52MdOvUmXOaNH6sOs9+/F+7bWPXdjlxG7u2y4nb2LVdF2/zwekelRYVas70T+jAu/8vpfNAycQCBYo/vq8u2TnZX3iJ5lWV6brLp2Ztv2LtiLX94nOipKTnyYvPn1MmDP1+21vatbnpuE6dOTdgv2pnTkn6b9H/XBp7rf/5O7ZNpv4NcnWfoM8Yk5U4tn79ej3xxBNqb2/XrFmz9OMf/1hz584d9vsikYj8fr/C4bCKi4sz3i4nrumSqmSVXGPhStKgr40keKVSNRaA++X5pHT/qJ80fozOXYjq7Lne7DQqRf3bHush7zyb+AfqLbOC+o//Exr2fDfSf4v+n3nxZw92/s6UTP4Bns71Oyvh45e//KXuuOMObdy4UTU1NfrRj36kF198UYcOHVJpaemQ35vt8OFWg1Vy7b/mQP/XJKU9NTfVqrEAAPvzKf3rQDLpXL+zcs/Hk08+qXvvvVd33323qqqqtHHjRo0fP15PP/10Nj7O84aq5DpUQIi9tnZrS8rjkelWjQUA2F8614FMyHj4OHfunA4cOKC6urqPPyQvT3V1dWpsbBywfU9PjyKRSMID6RlpJVcpsaR8tj8LAGA/6V4HMiHj4eODDz5Qb2+vysrKEp4vKytTe3v7gO3XrVsnv98ff1RUVGS6Sa6XiXLwqb6H3UvPAwBGxsrze86n2q5evVrhcDj+OHbsWK6b5DiZKAfPSrkA4G1Wnt8zPtV2ypQpys/P14kTJxKeP3HihAKBwIDtCwoKVFBQkOlmeMpwq9wOJd0VcEdSNRYAYF+5WAk94z0fY8eO1Zw5c7Rz5874c9FoVDt37lRtbW2mPw5KbZXboV5Lp6R87LPcMTkZACBZv7RIVoZdVq5cqX/913/Vc889pz/96U9qaGjQmTNndPfdd2fj46ChV7nduGy2NmZwBdzYZwX9DMEAXjeS69Wk8WMGVJ3OxR80/duerF1Bf6G+fkNlSue7/u83sSBfE8bmD/k9yT7z4s+Onb+zdb4N5mgl9KwVGfvJT34SLzL22c9+Vk899ZRqamqG/T7qfIwOFU7dV0nSKdvYtV1O3Mau7cp0hdOLz0fpvI/dK5wme79klUndVuE050XGRoPwAQCA8+S8yBgAAMBgCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUyvqrtaMUKrkYikRy3BAAApCp23U6lcLrtwkdXV5ckqaKiIsctAQAA6erq6pLf7x9yG9ut7RKNRnX8+HEVFRXJ58vcYjcVFRU6duyYK9eLYf+cjf1zNvbP2di/zDHGqKurS+Xl5crLG/quDtv1fOTl5enSSy/NynsXFxe78ocrhv1zNvbP2dg/Z2P/MmO4Ho8YbjgFAACWInwAAABLeSJ8FBQUaM2aNSooKMh1U7KC/XM29s/Z2D9nY/9yw3Y3nAIAAHfzRM8HAACwD8IHAACwFOEDAABYivABAAAs5frwsX79el122WUqLCxUTU2N9u/fn+smjci6det07bXXqqioSKWlpbr11lt16NChhG3++q//Wj6fL+HxjW98I0ctTs+jjz46oO1XXXVV/PXu7m4tX75ckydP1sSJE3X77bfrxIkTOWxxei677LIB++fz+bR8+XJJzjt2e/fu1aJFi1ReXi6fz6fNmzcnvG6M0SOPPKJgMKhx48aprq5Ohw8fTtjm1KlTWrp0qYqLizVp0iTdc889On36tIV7Mbih9u/8+fNatWqVrr76ak2YMEHl5eW64447dPz48YT3SHbMH3vsMYv3ZHDDHcO77rprQPvr6+sTtnHqMZSU9PfR5/PpiSeeiG9j12OYyvUglXPm0aNHdfPNN2v8+PEqLS3Vd7/7XV24cMGSfXB1+PjlL3+plStXas2aNTp48KBmzZqlBQsW6OTJk7luWtr27Nmj5cuX64033tD27dt1/vx5zZ8/X2fOnEnY7t5771UoFIo/Hn/88Ry1OH2f+cxnEtr+6quvxl974IEHtHXrVr344ovas2ePjh8/rttuuy2HrU3P73//+4R92759uyTpb/7mb+LbOOnYnTlzRrNmzdL69euTvv7444/rqaee0saNG7Vv3z5NmDBBCxYsUHd3d3ybpUuX6o9//KO2b9+ul19+WXv37tV9991n1S4Maaj9O3v2rA4ePKiHH35YBw8e1K9+9SsdOnRIt9xyy4Btv//97ycc029961tWND8lwx1DSaqvr09o//PPP5/wulOPoaSE/QqFQnr66afl8/l0++23J2xnx2OYyvVguHNmb2+vbr75Zp07d06vv/66nnvuOT377LN65JFHrNkJ42Jz5841y5cvj3/d29trysvLzbp163LYqsw4efKkkWT27NkTf+6v/uqvzLe//e3cNWoU1qxZY2bNmpX0tc7OTjNmzBjz4osvxp/705/+ZCSZxsZGi1qYWd/+9rfNzJkzTTQaNcY4+9hJMi+99FL862g0agKBgHniiSfiz3V2dpqCggLz/PPPG2OMaWlpMZLM73//+/g2v/3tb43P5zPvv/++ZW1PRf/9S2b//v1Gknn33Xfjz02fPt388Ic/zG7jMiTZPt55551m8eLFg36P247h4sWLzY033pjwnFOOYf/rQSrnzN/85jcmLy/PtLe3x7fZsGGDKS4uNj09PVlvs2t7Ps6dO6cDBw6orq4u/lxeXp7q6urU2NiYw5ZlRjgcliSVlJQkPP9v//ZvmjJliqqrq7V69WqdPXs2F80bkcOHD6u8vFwzZszQ0qVLdfToUUnSgQMHdP78+YRjedVVV2natGmOPJbnzp3Tpk2b9LWvfS1h8UQnH7uLtbW1qb29PeF4+f1+1dTUxI9XY2OjJk2apL/4i7+Ib1NXV6e8vDzt27fP8jaPVjgcls/n06RJkxKef+yxxzR58mR97nOf0xNPPGFZl3am7N69W6WlpbryyivV0NCgjo6O+GtuOoYnTpzQr3/9a91zzz0DXnPCMex/PUjlnNnY2Kirr75aZWVl8W0WLFigSCSiP/7xj1lvs+0WlsuUDz74QL29vQn/sJJUVlamP//5zzlqVWZEo1Hdf//9uu6661RdXR1//qtf/aqmT5+u8vJyvf3221q1apUOHTqkX/3qVzlsbWpqamr07LPP6sorr1QoFNLatWv1l3/5l2publZ7e7vGjh074MReVlam9vb23DR4FDZv3qzOzk7ddddd8eecfOz6ix2TZL97sdfa29tVWlqa8Poll1yikpISxx3T7u5urVq1SkuWLElYuOvv//7vNXv2bJWUlOj111/X6tWrFQqF9OSTT+awtamrr6/XbbfdpsrKSrW2tuqhhx7SwoUL1djYqPz8fFcdw+eee05FRUUDhnKdcAyTXQ9SOWe2t7cn/R2NvZZtrg0fbrZ8+XI1Nzcn3BMhKWGs9eqrr1YwGNRNN92k1tZWzZw50+pmpmXhwoXx/7/mmmtUU1Oj6dOn69///d81bty4HLYs8372s59p4cKFKi8vjz/n5GPnZefPn9ff/u3fyhijDRs2JLy2cuXK+P9fc801Gjt2rL7+9a9r3bp1tit1ncxXvvKV+P9fffXVuuaaazRz5kzt3r1bN910Uw5blnlPP/20li5dqsLCwoTnnXAMB7se2J1rh12mTJmi/Pz8AXf3njhxQoFAIEetGr0VK1bo5Zdf1iuvvKJLL710yG1ramokSUeOHLGiaRk1adIkXXHFFTpy5IgCgYDOnTunzs7OhG2ceCzfffdd7dixQ3/3d3835HZOPnaxYzLU714gEBhw4/eFCxd06tQpxxzTWPB49913tX379mGXK6+pqdGFCxf0zjvvWNPADJsxY4amTJkS/5l0wzGUpP/8z//UoUOHhv2dlOx3DAe7HqRyzgwEAkl/R2OvZZtrw8fYsWM1Z84c7dy5M/5cNBrVzp07VVtbm8OWjYwxRitWrNBLL72kXbt2qbKyctjvaWpqkiQFg8Esty7zTp8+rdbWVgWDQc2ZM0djxoxJOJaHDh3S0aNHHXcsn3nmGZWWlurmm28ecjsnH7vKykoFAoGE4xWJRLRv37748aqtrVVnZ6cOHDgQ32bXrl2KRqPx4GVnseBx+PBh7dixQ5MnTx72e5qampSXlzdgqMIp3nvvPXV0dMR/Jp1+DGN+9rOfac6cOZo1a9aw29rlGA53PUjlnFlbW6s//OEPCQEyFqKrqqos2QnXeuGFF0xBQYF59tlnTUtLi7nvvvvMpEmTEu7udYqGhgbj9/vN7t27TSgUij/Onj1rjDHmyJEj5vvf/7558803TVtbm9myZYuZMWOGueGGG3Lc8tQ8+OCDZvfu3aatrc289tprpq6uzkyZMsWcPHnSGGPMN77xDTNt2jSza9cu8+abb5ra2lpTW1ub41anp7e310ybNs2sWrUq4XknHruuri7z1ltvmbfeestIMk8++aR566234rM9HnvsMTNp0iSzZcsW8/bbb5vFixebyspK8+GHH8bfo76+3nzuc58z+/btM6+++qq5/PLLzZIlS3K1SwmG2r9z586ZW265xVx66aWmqakp4fcxNkvg9ddfNz/84Q9NU1OTaW1tNZs2bTJTp041d9xxR4737GND7WNXV5f5zne+YxobG01bW5vZsWOHmT17trn88stNd3d3/D2cegxjwuGwGT9+vNmwYcOA77fzMRzuemDM8OfMCxcumOrqajN//nzT1NRktm3bZqZOnWpWr15tyT64OnwYY8yPf/xjM23aNDN27Fgzd+5c88Ybb+S6SSMiKenjmWeeMcYYc/ToUXPDDTeYkpISU1BQYD71qU+Z7373uyYcDue24Sn68pe/bILBoBk7dqz55Cc/ab785S+bI0eOxF//8MMPzTe/+U3ziU98wowfP9588YtfNKFQKIctTt/vfvc7I8kcOnQo4XknHrtXXnkl6c/jnXfeaYzpm2778MMPm7KyMlNQUGBuuummAfvd0dFhlixZYiZOnGiKi4vN3Xffbbq6unKwNwMNtX9tbW2D/j6+8sorxhhjDhw4YGpqaozf7zeFhYXm05/+tPnnf/7nhAt3rg21j2fPnjXz5883U6dONWPGjDHTp083995774A/3Jx6DGP+5V/+xYwbN850dnYO+H47H8PhrgfGpHbOfOedd8zChQvNuHHjzJQpU8yDDz5ozp8/b8k++D7aEQAAAEu49p4PAABgT4QPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFjq/wMZab+MMx3Q/gAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Indices of selected features: [13, 14, 173, 8, 175, 15, 16, 3, 17, 7, 30, 20]\n","Values of selected features: [20.63974, 19.92032, 16.20907, 13.91057, 13.49403, 12.68193, 12.41004, 10.74214, 10.62536, 10.57722, 8.899038, 8.477417]\n","stcpb\n","dtcpb\n","service_-\n","dload\n","service_dns\n","smeansz\n","dmeansz\n","sttl\n","trans_depth\n","sload\n","ct_ftp\n","djit\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3e4762130c52>\u001b[0m in \u001b[0;36m<cell line: 131>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mnum_examples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m508012\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mselect_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mselect_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mselect_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-3e4762130c52>\u001b[0m in \u001b[0;36mselect_feature\u001b[0;34m(file, num_examples, indices)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mdata_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    973\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    974\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                            run_metadata)\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1383\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1478\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                             run_metadata)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["get_indices(num_select, num_feature, file_weights)"],"metadata":{"id":"AvLbl6KqcKO3","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1720217111341,"user_tz":420,"elapsed":681,"user":{"displayName":"Minh Pham","userId":"10257624266917738519"}},"outputId":"3dc2dbe6-8425-4829-8d70-049adf86d937"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Indices of selected features: [13, 14, 173, 8, 175, 15, 16, 3, 17, 7, 30, 20]\n","Values of selected features: [20.63974, 19.92032, 16.20907, 13.91057, 13.49403, 12.68193, 12.41004, 10.74214, 10.62536, 10.57722, 8.899038, 8.477417]\n"]},{"output_type":"execute_result","data":{"text/plain":["[13, 14, 173, 8, 175, 15, 16, 3, 17, 7, 30, 20]"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]}]}